
Persona Notes on progress of this app below: 

Goal: Learning how to work with golang, google cloud api, and speech recognition

RESOURCE -
https://medium.com/@ODSC/quick-start-for-golang-google-cloud-api-and-speech-recognition-f157cda1ce5c

CREATING A SERVICE ACCOUNT -
Setting up a Google Cloud API account: https://cloud.google.com/docs/authentication/getting-started#auth-cloud-implicit-go 

SECURITY -
Managing service account keys: https://cloud.google.com/iam/docs/understanding-service-accounts?hl=en_US&_ga=2.101743105.-1015558750.1559092652#managing_service_account_keys

Securing keys with GODOTENV - 
https://github.com/joho/godotenv

Still unclear:
Is my secret configuration working?
How to get an audio file?
How to import that file into application?

Get the Client Library Tutorial: https://github.com/Drizzy3D/go-speech-recognition-lib

TESTING RESULT 1:
-2019/06/21 12:54:47 Failed to recognize: rpc error: code = PermissionDenied desc = Cloud Speech-to-Text API has not been used in project "soandso" before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/speech.googleapis.com/overview?project="soandso" then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.
-Enabled API, needed to set up billing account. Free 12months or $300 credit!

TESTING RESULT 2: 
-Passed! "how old is the Brooklyn Bridge (confidence=0.983505)"

NEW GOAL:
Next step is to figure out to make these changes in realtime..I'm thinking that I need to add to the audio file based on speech. It may get delayed as the audiofile changes. Perhaps I can parse a new audiofile every 10 seconds? Not sure if concurrency will help.

Resources: https://cloud.google.com/speech-to-text/docs/streaming-recognize

gcloud tool: https://cloud.google.com/speech-to-text/docs/quickstart


TESTING RESULT 1: 
2019/06/21 13:39:53 Warning: Speech recognition request exceeded limit of 60 seconds.
2019/06/21 13:39:53 Could not recognize: code:11 message:"Audio Timeout Error: Long duration elapsed without audio. Audio should be sent close to real time." 
-I don't think the program is recognizing the audio from my mic.


Google Cloud SDK Documentation: 
https://cloud.google.com/sdk/docs/
https://cloud.google.com/speech-to-text/docs/quickstart-gcloud

Installation for GO: https://cloud.google.com/appengine/docs/standard/go/download

Steps: Needed to gcloud init and authorize Google Cloud SDK
Confirmation page: https://cloud.google.com/sdk/auth_success

GOAL: test gcloud and code locally

TEST 1: ERROR
PASSED IN - /Users/xavierolivares/go/src/projects/speechtest/audio.raw
RESULT - 2019/06/21 15:40:22 Please pass path to y
our local audio file as a command line ar
gument


TEST 2: SUCCESS
PASSED IN - go build && ./speechtest /Users/xav
ierolivares/go/src/projects/speechtest/au
dio.raw
RESULT - Result: alternatives:<transcript:"how old
 is the Brooklyn Bridge" confidence:0.983
5046 > is_final:true result_end_time:<sec
onds:1 nanos:770000000 > 

FINDING MIC CODES: gst-device-monitor-1.0

REQUIRED: Need to insert mic input into command line with gst-launch1.0.

FOUND this: gst-launch-1.0 osxaudiosrc device=40

Questions:
thirdlevel branch: how can i get the microphone to link up with this code?

stretch:
Is it possible to get results to render on html page?

TAKEAWAYS: how to run audio file locally with cat and livecaption
cat ./audio.raw | go run liv
ecaption.go

//Configure gcloud credentials for communicating with SpeechToText API

export GOOGLE_APPLICATION_CREDENTIALS=[PATH TO CREDENTIALS JSON]

gst-launch-1.0 -v osxaudiosrc device=40 ! audioconvert ! audioresample ! audio/x-raw,channels=1,rate=16000 ! filesink location=/dev/stdout | go run livecaption.go

gst-launch-1.0 -v osxaudiosrc device=39 ! audioconvert ! audioresample ! audio/x-raw,channels=1,rate=16000 ! filesink location=/dev/stdout | go run *.go

Running local file:
cat ./audio.raw | go run *.go

Doesn't work with bluetooth, at least yet.

---


SPEECH RECOGNITION WITH AUDIO FILE

import (
	"fmt"
	// "net/http"
	"io/ioutil"

	speech "cloud.google.com/go/speech/apiv1"
	"golang.org/x/net/context"
	speechpb "google.golang.org/genproto/googleapis/cloud/speech/v1"

	// "github.com/joho/godotenv"
	"log"
	// "os"
)

func main() {
	fmt.Println("Hello Fullstack Fam!")

	//ERROR HANDLING FOR GOOGLE_APPLICATION_CREDENTIALS
	// err := godotenv.Load()
	// if err != nil {
	// 	log.Fatal("Error loading .env file")
	// }
	// googleKey := os.Getenv("GOOGLE_APPLICATION_CREDENTIALS")

	//ERROR HANDLING IF API HAS NOT COMPLETED A REQUEST
	ctx := context.Background()

	client, err := speech.NewClient(ctx)
	if err != nil {
		log.Fatalf("Failed to create client: %v", err)
	}

	//PATH TO AUDIO FILE .raw file
	filename := "/Users/xavierolivares/go/src/projects/speechtest/audio.raw"

	//ERROR HANDLING FOR CONNECTING TO AUDIO FILE
	audioData, err := ioutil.ReadFile(filename)
	if err != nil {
		log.Fatalf("Failed to read file: %v", err)
	}

	response, err := client.Recognize(ctx, &speechpb.RecognizeRequest{
		Config: &speechpb.RecognitionConfig{
			Encoding:        speechpb.RecognitionConfig_LINEAR16,
			// SampleRateHertz: 8000,
			// SampleRateHertz: 11025,
			SampleRateHertz: 16000,
			LanguageCode:    "en-US",
		},
		Audio: &speechpb.RecognitionAudio{
			AudioSource: &speechpb.RecognitionAudio_Content{Content: audioData},
		},
	})

	if err != nil {
		log.Fatalf("Failed to recognize: %v", err)
	}
	//PRINTS THE RESULT
	for _, result := range response.Results {
		for _, alt := range result.Alternatives {
			// fmt.Println(alt.Transcript)
			fmt.Printf("\"%v\" (confidence=%3f)\n", alt.Transcript, alt.Confidence)
		}
	}
}


LOCAL TEST WITH GCLOUD 

import (
	"context"
	"flag"
	"fmt"
	"io"
	"log"
	"os"
	"path/filepath"

	speech "cloud.google.com/go/speech/apiv1"
	speechpb "google.golang.org/genproto/googleapis/cloud/speech/v1"
)

func main() {
	flag.Usage = func() {
		fmt.Fprintf(os.Stderr, "Usage: %s <AUDIOFILE>\n", filepath.Base(os.Args[0]))
		fmt.Fprintf(os.Stderr, "<AUDIOFILE> must be a path to a local audio file. Audio file must be a 16-bit signed little-endian encoded with a sample rate of 16000.\n")

	}
	flag.Parse()
	if len(flag.Args()) != 1 {
		log.Fatal("Please pass path to your local audio file as a command line argument")
	}
	audioFile := flag.Arg(0)

	ctx := context.Background()

	client, err := speech.NewClient(ctx)
	if err != nil {
		log.Fatal(err)
	}
	stream, err := client.StreamingRecognize(ctx)
	if err != nil {
		log.Fatal(err)
	}
	// Send the initial configuration message.
	if err := stream.Send(&speechpb.StreamingRecognizeRequest{
		StreamingRequest: &speechpb.StreamingRecognizeRequest_StreamingConfig{
			StreamingConfig: &speechpb.StreamingRecognitionConfig{
				Config: &speechpb.RecognitionConfig{
					Encoding:        speechpb.RecognitionConfig_LINEAR16,
					SampleRateHertz: 16000,
					LanguageCode:    "en-US",
				},
			},
		},
	}); err != nil {
		log.Fatal(err)
	}

	f, err := os.Open(audioFile)
	if err != nil {
		log.Fatal(err)
	}
	defer f.Close()

	go func() {
		buf := make([]byte, 1024)
		for {
			n, err := f.Read(buf)
			if n > 0 {
				if err := stream.Send(&speechpb.StreamingRecognizeRequest{
					StreamingRequest: &speechpb.StreamingRecognizeRequest_AudioContent{
						AudioContent: buf[:n],
					},
				}); err != nil {
					log.Printf("Could not send audio: %v", err)
				}
			}
			if err == io.EOF {
				// Nothing else to pipe, close the stream.
				if err := stream.CloseSend(); err != nil {
					log.Fatalf("Could not close stream: %v", err)
				}
				return
			}
			if err != nil {
				log.Printf("Could not read from %s: %v", audioFile, err)
				continue
			}
		}
	}()

	for {
		resp, err := stream.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("Cannot stream results: %v", err)
		}
		if err := resp.Error; err != nil {
			log.Fatalf("Could not recognize: %v", err)
		}
		for _, result := range resp.Results {
			fmt.Printf("Result: %+v\n", result)
		}
	}
}

STREAMING - FAILING

import (
	"context"
	"fmt"
	"io"
	"log"
	"os"

	speech "cloud.google.com/go/speech/apiv1"
	speechpb "google.golang.org/genproto/googleapis/cloud/speech/v1"
)

func main() {
	ctx := context.Background()

	client, err := speech.NewClient(ctx)
	if err != nil {
		log.Fatal(err)
	}
	stream, err := client.StreamingRecognize(ctx)
	if err != nil {
		log.Fatal(err)
	}
	// Send the initial configuration message.
	if err := stream.Send(&speechpb.StreamingRecognizeRequest{
		StreamingRequest: &speechpb.StreamingRecognizeRequest_StreamingConfig{
			StreamingConfig: &speechpb.StreamingRecognitionConfig{
				Config: &speechpb.RecognitionConfig{
					Encoding:        speechpb.RecognitionConfig_LINEAR16,
					SampleRateHertz: 16000,
					LanguageCode:    "en-US",
				},
			},
		},
	}); err != nil {
		log.Fatal(err)
	}

	go func() {
		// Pipe stdin to the API.
		buf := make([]byte, 1024)
		for {
			n, err := os.Stdin.Read(buf)
			if n > 0 {
				if err := stream.Send(&speechpb.StreamingRecognizeRequest{
					StreamingRequest: &speechpb.StreamingRecognizeRequest_AudioContent{
						AudioContent: buf[:n],
					},
				}); err != nil {
					log.Printf("Could not send audio: %v", err)
				}
			}
			if err == io.EOF {
				// Nothing else to pipe, close the stream.
				if err := stream.CloseSend(); err != nil {
					log.Fatalf("Could not close stream: %v", err)
				}
				return
			}
			if err != nil {
				log.Printf("Could not read from stdin: %v", err)
				continue
			}
		}
	}()

	for {
		resp, err := stream.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			log.Fatalf("Cannot stream results: %v", err)
		}
		if err := resp.Error; err != nil {
			// Workaround while the API doesn't give a more informative error.
			if err.Code == 3 || err.Code == 11 {
				log.Print("WARNING: Speech recognition request exceeded limit of 60 seconds.")
			}
			log.Fatalf("Could not recognize: %v", err)
		}
		for _, result := range resp.Results {
			fmt.Printf("Result: %+v\n", result)
		}
	}
}
